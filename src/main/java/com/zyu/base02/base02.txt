转换算子
map,filter,flatMap
map:一对一
filter:过滤
flatMap:一对多

聚合算子
sum,min,minBy,max,maxBy,reduce
sum:求和
min,minBy,max,maxBy: min返回的是最小值,minBy返回的是该字段中具有最小值的元素(max,maxBy同理)
reduce:当流中只有一条数据时,不会执行reduce

富函数:
1.所有Flink函数类都有其Rich版本
2.富函数有一个生命周期的概念
    open() 初始化
    close() 结束
    getRuntimeContext() 提供函数执行的并行度,任务名字,state状态等

分区算子 (学习文档：https://www.hangge.com/blog/cache/detail_3841.html)
shuffle(随机分区)：将上游数据随机分发到下游算子实例的每个分区中
    (底层对应的是ShufflePartitioner这个类，类里面有一个selectChannel函数，这个函数会计算数据将会被发送哪个分区，里面是random.nextInt，是随机的)
rebalance(重平衡分区)：将输出元素以轮询方式均匀地分布到下一个算子的实例中,有助于均匀地分布数据
    (底层对应的是RebalancePartitioner这个类，类里面有一个setup和selectChannel函数，setup函数会根据分区数初始化一个随机值nextChannelToSendTo，
    然后 selectChannel 函数会使用 nextChannelToSendTo 加 1 和分区数取模，把计算的值再赋给 nextChannelToSendTo ，
    后面以此类推，其实就可以实现向下游算子实例的多个分区循环发送数据了，这样每个分区获取到的数据基本一致)
rescale(重分区)：将输出元素以轮询的方式均匀地分布下一个算子的实例子集
    (底层对应的是RescalePartitioner这个类类里面有一个 selectChannel 函数，这里面的 numberOfChannels 是分区数量，其实也可以认为是我们所说的算子的并行度，因为一个分区是由一个线程负责处理的，它们两个是一一对应的)
broadcast(广播分区)：将输出元素广播到下一个算子的每个并行实例，适合于大数据集Join小数据集的场景，可以提高性能
    (底层对应的是 BroadcastPartitioner 这个类。看这个类中的 selectChannel 函数代码的注释，提示广播分区不支持选择 Channel，因为会输出数据到下游的每个 Channel 中，就是发送到下游算子实例的每个分区中)
global(全局分区)：将所有数据发送到下游的一个并行子任务中
    (该方法使用 GlobalPartitioner 分区程序来设置 DataStream 的分区，以便将输出值都转到下一个处理操作符（算子）的第一个实例。使用此设置时要小心，因为它可能会在应用程序中造成严重的性能瓶颈。)
keyBy(按键分区)：根据 key 的分组索引选择目标通道，将输出元素发送到相对应的下游分区
    (使用 KeyGroupStreamPartitioner 分区程序来设置 DataStream 的分区)
forward(转发分区)：将输出元素被转发到下一个操作（算子）的本地子任务
    (在上下游的算子没有指定分区器的情况下，如果上下游的算子并行度一致，则使用 ForwardPartitioner，否则使用 RebalancePartitioner。
    对于 ForwardPartitioner，必须保证上下游算子并行度一致，即上有算子与下游算子是 1 对 1 的关系，否则会抛出异常。)
    (forward 方法使用 ForwardPartitioner 分区程序来设置 DataStream 的分区，仅将元素转发到本地运行的下游操作（算子）)
custom partition(自定义分区)：自定义分区策略的 API 为 CustomPartitionerWrapper。该策略允许开发者自定义规则将上游算子元素发送到下游指定的算子实例中。
              使用该分区策略首先我们需要新建一个自定义分区器，然后使用这个自定义分区器进行分区。

分流：
filter：本质工作是过滤，如果通过filter进行分流的话，同一条流可能会被处理多次，效率低，所以一般不用
侧输出流：原理是对流中数据进行处理的时候，给元素打标签，所以使用侧输出流的时候，需要先创建标签对象，创建标签对象的时候，需要注意会存在泛型擦除问题
        (以匿名内部类方式创建对象，在创建对象时，指定泛型类型)
合流：
union：可以合并两条流或者多条流，参与合并的流的数据类型必须一致
connect：对两条流就行合并